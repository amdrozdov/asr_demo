{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fabc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sulverus/dev/asr/sentiment/env/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "import random\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab2f9c8",
   "metadata": {},
   "source": [
    "### Basic tokenisation with spacy\n",
    "In order to process original text we will use spacy default en model as tokenizer (instead of using default string.split function) and will use vocabulary to collect a set of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5dcba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "TEXT = data.Field(tokenize = 'spacy',\n",
    "                  tokenizer_language = 'en_core_web_sm',\n",
    "                  include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0588b95",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "For demonstration I will use IMDB movie review dataset, which is available in torchtext library\n",
    "and it was used for sentiment analysis in many publications.\n",
    "In order to check overfitting we have to split dataset into 3 parts:\n",
    "* training set - will be used for training of ANN\n",
    "* validation set - will be used for validation during training\n",
    "* test set - hidden data set in order to check the model after training process in separate data (this data was not used for training and validation)\n",
    "\n",
    "### Strategy\n",
    "Our goal is to get the prediction score as a continious value from -1 to 1, where -1 is negative, 0 is neutral and 1 is positive. In this dataset we have only negative and positive lables. But we can train the model as binary classifier that will return 0 for negative and 1 for positive sentiment. We can map the output of the ANN to the interval(-1;1). Alternative solution is to train multiclass classifier and use probability of each class in order to get the final score. But binary classifier is good solution for this dataset(we don't have neutarl lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a255ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47eb3a",
   "metadata": {},
   "source": [
    "### Dataset lables sanity check\n",
    "Here we can see that ratio for positive and negative labels for each dataset is around 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1cf9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set has 8690/8810 positive/negative samples balance=0.99\n",
      "test set has 12500/12500 positive/negative samples balance=1.00\n",
      "valid set has 3810/3690 positive/negative samples balance=1.03\n"
     ]
    }
   ],
   "source": [
    "def check_balance(ds, name):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for row in ds:\n",
    "        if row.label == 'pos':\n",
    "            positive += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "    print(name + \" has %s/%s positive/negative samples\" % (positive, negative), 'balance=%.02f' % float(positive/negative))\n",
    "    \n",
    "check_balance(train_data, \"train set\")\n",
    "check_balance(test_data, \"test set\")\n",
    "check_balance(valid_data, \"valid set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37d7d0",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "In the beginning I was thinkng about word2vec embeddings, but currently glove embeddings are much more advanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41cbdd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d984df0",
   "metadata": {},
   "source": [
    "### Create training pipeline\n",
    "In order to train our model I will create iterators based on train, test and validation datasets\n",
    "In addition I will try to train all models with Cuda on my old nVidia card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa79e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "DEVICE_NAME = 'cuda'\n",
    "device = torch.device(DEVICE_NAME)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b335c5",
   "metadata": {},
   "source": [
    "### Model\n",
    "In this case we have more advanced model:\n",
    "* Glove embedding as input (vector size=100)\n",
    "* Recurrent neural network (LSTM) layer\n",
    "* Linear layer for hidden layer+output layer\n",
    "* Dropout layer for regularisation - randomly zeroing some elements of the input tensor with probability P using samples from a Bernoulli distribution. This is known and effective technique for regularisation\n",
    "\n",
    "Important:\n",
    "Unfortunatly my local PC is a bit old and it will take tonns of time to train really good model, I was trying to artificially prune/simplify the model in order to debug the pipeline and get some results in less then 5-6 hours.\n",
    "You can see that hidden layer size is reduced to 16 (but in powerfull PR it can be 128, 256 or even more)\n",
    "\n",
    "Remark:\n",
    "If i set hidden layer size to 256 - i will get around 4.5mln parameters, the result of prunning/simplification is 2.5 mln parameters\n",
    "\n",
    "Remark 2:\n",
    "I was trying to run bigger hidden layer size, but I was always getting cuda memory errors\n",
    "\n",
    "Remark 3:\n",
    "In addition it will be interesting to add accustic data from audio inference in order to use text and audio data for sentiment analysis (not implemented in this version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d154ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b1f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 16#256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003e348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params=2521737\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable params={total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778fdd1",
   "metadata": {},
   "source": [
    "### Glove embedings\n",
    "Here we have to add glove embeddings and check that they are not empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf74dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7261cf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
       "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.0817,  0.5434,  0.6970,  ..., -0.6586,  0.0563,  0.3244],\n",
       "        [ 0.3190, -0.1413, -0.3953,  ...,  0.6556, -0.0397,  0.1782],\n",
       "        [ 0.2340, -0.4945, -0.1938,  ...,  0.0156,  1.0351,  0.8970]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bafdbf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [-0.0817,  0.5434,  0.6970,  ..., -0.6586,  0.0563,  0.3244],\n",
      "        [ 0.3190, -0.1413, -0.3953,  ...,  0.6556, -0.0397,  0.1782],\n",
      "        [ 0.2340, -0.4945, -0.1938,  ...,  0.0156,  1.0351,  0.8970]])\n"
     ]
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04629efe",
   "metadata": {},
   "source": [
    "### Training\n",
    "For this experiment i will keep binary cross entropy loss function with sigmoid layer, but instead of SGD optimiser I will use Adaptive learning rate optimisation (which is more efficient then default SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b67d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fb9f3",
   "metadata": {},
   "source": [
    "### Training functions\n",
    "In order to do training and validation I will ned some auxilarity functions\n",
    "* accuracy calculation\n",
    "* training loop\n",
    "* evaluation loop (which will use accuracy function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32e5e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c93dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, text_lengths = batch.text\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4a5a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2697ec04",
   "metadata": {},
   "source": [
    "### Main training loop\n",
    "Here you can see limited amount of epochs(5) and cuda memory limitation (500mb) in order to be able to get a model in a reasonable amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97afeea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.688 | Train Acc: 53.56%\n",
      "\t Val. Loss: 0.635 |  Val. Acc: 64.55%\n",
      "Epoch: 02 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.586 | Train Acc: 69.76%\n",
      "\t Val. Loss: 0.542 |  Val. Acc: 74.34%\n",
      "Epoch: 03 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.497 | Train Acc: 76.87%\n",
      "\t Val. Loss: 0.443 |  Val. Acc: 81.11%\n",
      "Epoch: 04 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.418 | Train Acc: 82.00%\n",
      "\t Val. Loss: 0.431 |  Val. Acc: 81.55%\n",
      "Epoch: 05 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.426 | Train Acc: 81.83%\n",
      "\t Val. Loss: 0.476 |  Val. Acc: 80.96%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:500\"\n",
    "MODEL_OUTPUT = 'sentiment_lstm_glove.pt'\n",
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_OUTPUT)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {elapsed_mins}m {elapsed_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82b6d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('embeddings.pickle', 'wb') as f:\n",
    "    pickle.dump(TEXT, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2f08c",
   "metadata": {},
   "source": [
    "### Final results\n",
    "In the end I can load the model and evalueate it on hidden dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c88836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.446 | Test Acc: 80.56%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_OUTPUT))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d1c12",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "For the advanced version with LSTM, Glove embeddings, and adaptive learning rate optimization we got 80.5% of accuracy which is significantly better than the baseline model. Due to lack of CPU/Memory on my PC, I expect that 80.5% is a good result for the interview exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e41627",
   "metadata": {},
   "source": [
    "### Prod inference\n",
    "Before we will start the segmentation pipeline we have to check potential prod code for the web service\n",
    "I will cover this topic in this section. For baseline we can simply filter all not alphanumeric numbers and split the line on words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f749b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "import re\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    st = re.sub(r'[^A-Za-z0-9 ]+', '', sentence)\n",
    "    tokenized = st.split(' ')\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99b893be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8141034245491028"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"It's a lovely day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bb5b8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.291689395904541"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"I hate brokkoli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b611b",
   "metadata": {},
   "source": [
    "### Score mapping\n",
    "Orignal goal of the exercise is to have continious value from -1 to 1, but we have continious value from 0 to 1. We can map interval from 0 to 1 to the interval from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edf25d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(text):\n",
    "    return predict_sentiment(model, text) * 2.0 - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfcd10e",
   "metadata": {},
   "source": [
    "### Santity checks\n",
    "After all experiments it's good to run simple checks and validate that models returns reasonable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63b5ce61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5232957899570465"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of negative sentence\n",
    "sentiment_score(\"I hate terribale brokkoli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28f0b7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07505971193313599"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of neutral sentence\n",
    "sentiment_score(\"I will read a book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42c05b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6282068490982056"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of positive sentence\n",
    "sentiment_score(\"It's a lovely day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0075009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
